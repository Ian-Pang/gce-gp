{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edr76/.conda/envs/jax/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "from healpy.newvisufunc import projview, newprojplot\n",
    "from astropy.io import fits\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import corner\n",
    "import os\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc_file('../utils/matplotlibrc')\n",
    "\n",
    "from utils import ed_fcts_amarel as ef\n",
    "from utils import create_mask as cm\n",
    "from utils import ed_plotting as eplt\n",
    "\n",
    "# load GPU\n",
    "gpu_id = '3'\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "\n",
    "from models.poissonian_gp import EbinPoissonModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SVI fit results (these should be the only parameters that you are loading)\n",
    "sim_seeds = np.arange(1000,1010)\n",
    "\n",
    "# name of the synthetic directory\n",
    "sim_name = 'canon_g1p2_ola_v2'\n",
    "\n",
    "# load SVI fit results (these should be the only parameters that you are loading)\n",
    "sim_id = 7.1234567\n",
    "temp_id = 5.23457\n",
    "gp_id = 1.16\n",
    "blg_id = -1\n",
    "mod_id = 11\n",
    "svi_id = 7840 # (24,25) =  (no outer roi, outer roi)\n",
    "sim_seed = 1000\n",
    "svi_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GPU\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "\n",
    "data_dir = ef.load_data_dir(sim_name)\n",
    "os.system(\"mkdir -p \"+data_dir)\n",
    "\n",
    "# Load the simulated templates\n",
    "ebin = 10\n",
    "temp_dict = np.load(data_dir + 'all_templates_ebin' + str(ebin)  + '.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "    settings_7p1234567_5p23457_1p16_-1_11_7840_1000_0.py\n",
      "    ebin10_svi_res_0.1_20000_mvn_8_1000_0.p\n",
      "    ebin_old10_smp_svi_0.1_20000_mvn_8_1000_0.p\n",
      "    __init__.py\n",
      "    summary.txt\n",
      "    ebin10_smp_svi_0.1_20000_mvn_8_1000_0.p\n",
      "__pycache__/\n",
      "    settings_7p1234567_5p23457_1p16_-1_11_7840_1000_0.cpython-311.pyc\n"
     ]
    }
   ],
   "source": [
    "fit_filename, module_name = ef.generate_fit_filename_from_ids(sim_id, temp_id, gp_id, blg_id, mod_id, svi_id, sim_seed, svi_seed)\n",
    "fit_dir = data_dir + 'fits/' + fit_filename + '/'\n",
    "ef.list_files(fit_dir)\n",
    "\n",
    "sys.path.append(fit_dir)\n",
    "import importlib \n",
    "module = importlib.import_module(module_name)\n",
    "\n",
    "# Load all the variables from the module\n",
    "globals().update(vars(module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model using stored parameters\n",
    "ebinmodel = EbinPoissonModel(\n",
    "        # important parameters\n",
    "        rig_temp_list = rig_temp_list,\n",
    "        hyb_temp_list = hyb_temp_list,\n",
    "        var_temp_list = var_temp_list,\n",
    "        is_gp = is_gp,\n",
    "        gp_deriv = gp_deriv,\n",
    "        data_file = data_file,\n",
    "        rig_temp_sim = rig_temp_sim,\n",
    "        hyb_temp_sim = hyb_temp_sim,\n",
    "        var_temp_sim = var_temp_sim,\n",
    "        is_custom_blg = is_custom_blg,\n",
    "        custom_blg_id = custom_blg_id,\n",
    "        sim_seed = sim_seed,\n",
    "        Nu = Nu,\n",
    "        u_option = u_option,\n",
    "        u_grid_type = u_grid_type,\n",
    "        u_weights = u_weights,\n",
    "        Np = Np,\n",
    "        p_option = p_option,\n",
    "        Nsub = Nsub,\n",
    "\n",
    "        # default parameters\n",
    "        ebin = ebin,\n",
    "        is_float64 = is_float64,\n",
    "        debug_nans = debug_nans,\n",
    "        no_ps_mask = no_ps_mask,\n",
    "        p_grid_type = p_grid_type,\n",
    "        p_weights = p_weights,\n",
    "        gp_kernel = gp_kernel,\n",
    "        gp_params = gp_params,\n",
    "        gp_scale_option = gp_scale_option,\n",
    "        monotonicity_hyperparameter = monotonicity_hyperparameter,\n",
    "        nfw_gamma = nfw_gamma,\n",
    "        blg_names = blg_names,\n",
    "        dif_names = dif_names,\n",
    "        )\n",
    "# configure model, run SVI, and generate samp \n",
    "ebinmodel.config_model(ebin=ebin)\n",
    "mask_p = ebinmodel.mask_roi_arr[ebin]\n",
    "mask = cm.make_mask_total(\n",
    "        nside=128,\n",
    "        mask_ring=True,\n",
    "        outer = 20.,\n",
    "        inner = 0.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_samples(samples, n_samples):\n",
    "    for key in samples.keys():\n",
    "        samples[key] = samples[key][:n_samples]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "idx : 100%|██████████| 3/3 [00:00<00:00, 33288.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231, 132, 123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_mod_id(dif_models, mod_data):\n",
    "    models = ['o', 'a', 'f']\n",
    "    num_dict = {m : str(i+1) for i, m in enumerate(models)}\n",
    "\n",
    "    mod_id = [num_dict[i] for i in dif_models]\n",
    "    mod_id.append(num_dict[mod_data])\n",
    "    mod_id = ''.join(mod_id)\n",
    "    return int(mod_id)\n",
    "\n",
    "mod_ids = []\n",
    "\n",
    "# dif_mods = [['o'], ['a'], ['f']]\n",
    "# data_mods = ['o', 'a', 'f']\n",
    "# gpu_id = '0'\n",
    "\n",
    "# txt = lambda x: ('\\\"' + str(x) + '\\\"')\n",
    "\n",
    "# for df in tqdm(dif_mods, desc = 'dif_mod', position = 0):\n",
    "#     for dm in tqdm(data_mods, desc = 'dat_mod', position = 1, leave = False):\n",
    "#         mod_ids.append(build_mod_id(df, dm))\n",
    "\n",
    "print('-----------------------------------')\n",
    "dif_mods = [['a', 'f'], ['o', 'f'], ['o', 'a']]\n",
    "data_mods = ['o', 'a', 'f']\n",
    "\n",
    "for i in tqdm(range(len(dif_mods)), desc = 'idx '):\n",
    "    df = dif_mods[i]\n",
    "    dm = data_mods[i]\n",
    "    mod_ids.append(build_mod_id(df, dm))\n",
    "\n",
    "# print('-----------------------------------')\n",
    "# dif_mods = [['o', 'a', 'f']]\n",
    "# data_mods = ['o', 'a', 'f']\n",
    "\n",
    "# for dm in tqdm(data_mods):\n",
    "#     df = dif_mods[0]\n",
    "#     mod_ids.append(build_mod_id(df, dm))\n",
    "\n",
    "# mod_ids.reverse()\n",
    "print(mod_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartesian map of masks to keep track of masking for plots\n",
    "n_pixels = 160 # 160 is our best choice\n",
    "mask_p = ebinmodel.mask_roi_arr[ebin]\n",
    "mask = cm.make_mask_total(\n",
    "        nside=128,\n",
    "        mask_ring=True,\n",
    "        outer = 20.,\n",
    "        inner = 0.,\n",
    "    )\n",
    "mask_map = np.zeros((~ebinmodel.mask_roi_arr[ebin]).sum())\n",
    "mask_map_cart = ef.healpix_to_cart(mask_map, ebinmodel.mask_roi_arr[ebin], n_pixels = n_pixels, nside = 128, nan_fill = True) # doesn't matter what mask used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mod_id:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mod_id: 100%|██████████| 3/3 [19:23<00:00, 387.73s/it]t]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# We'll start with the difficult stuff\n",
    "# We'll start by making the single model fits\n",
    "\n",
    "def build_mod_id(dif_models, mod_data):\n",
    "    models = ['o', 'a', 'f']\n",
    "    num_dict = {m : str(i+1) for i, m in enumerate(models)}\n",
    "\n",
    "    mod_id = [num_dict[i] for i in dif_models]\n",
    "    mod_id.append(num_dict[mod_data])\n",
    "    mod_id = ''.join(mod_id)\n",
    "    return int(mod_id)\n",
    "\n",
    "temp_dict_list = {}\n",
    "temp_sample_dict_list = {}\n",
    "temp_sample_dict_cmask_list = {}\n",
    "exp_gp_samples_cart_list = {}\n",
    "gp_true_cart_list = {}\n",
    "tot_samples_cart_list = {}\n",
    "model_residuals_cart_list = {}\n",
    "\n",
    "for mod_id in tqdm(mod_ids, desc = 'mod_id', position = 0):\n",
    "    data_models = ['o', 'a', 'f']\n",
    "    mod_data = data_models[int(str(mod_id)[-1]) - 1]\n",
    "    sim_name = data_file = 'canon_g1p2_{}la_v2'.format(mod_data)\n",
    "    data_dir = ef.load_data_dir(sim_name)\n",
    "\n",
    "    temp_dict = np.load(data_dir + 'all_templates_ebin' + str(ebin)  + '.npy', allow_pickle=True).item()\n",
    "    temp_dict_list[mod_id] = temp_dict\n",
    "\n",
    "    aug_temp_sample_dict = []\n",
    "    aug_temp_sample_dict_cmask = []\n",
    "    aug_exp_gp_samples_cart = []\n",
    "    aug_gp_true_cart = []\n",
    "    aug_tot_samples_cart = []\n",
    "    aug_model_residuals_cart = []\n",
    "\n",
    "    for sim_seed in tqdm(sim_seeds, desc = 'sim_seed', position = 1, leave = False):\n",
    "        str_sim_seed = str(sim_seed)\n",
    "        \n",
    "        # load file names and data\n",
    "        fit_filename, module_name = ef.generate_fit_filename_from_ids(sim_id, temp_id, gp_id, blg_id, mod_id, svi_id, sim_seed, svi_seed)\n",
    "        fit_dir = data_dir + 'fits/' + fit_filename + '/'\n",
    "        # ef.list_files(fit_dir)\n",
    "\n",
    "        # sys.path.append(fit_dir)\n",
    "        # import importlib \n",
    "        # module = importlib.import_module(module_name)\n",
    "\n",
    "        # # Load all the variables from the module\n",
    "        # globals().update(vars(module))\n",
    "\n",
    "        file_name = ('ebin' + str_ebin + '_smp_svi_' + \n",
    "                    str_lr + '_' + str_n_steps + '_' + \n",
    "                        str_guide + '_' + str_num_particles + '_' + \n",
    "                        str_sim_seed + '_' + str_svi_seed + '.p')\n",
    "        samples_dict, _ = pickle.load(open(fit_dir + file_name, 'rb'))\n",
    "\n",
    "        # generate temp_sample_dict (less samples)\n",
    "        all_temp_names = ['iso', 'psc', 'bub', 'pib', 'ics', 'blg', 'nfw', 'dsk', 'gp']\n",
    "        names = list(samples_dict.keys())\n",
    "        temp_sample_dict = {k: samples_dict[k] for k in all_temp_names if k in names}\n",
    "        temp_sample_dict_cmask = {k: samples_dict[k + '_cmask'] for k in all_temp_names if k in names}\n",
    "\n",
    "        temp_sample_dict = truncate_samples(temp_sample_dict, 100)\n",
    "        temp_sample_dict_cmask = truncate_samples(temp_sample_dict_cmask, 100)\n",
    "\n",
    "        # save temp_sample_dict\n",
    "        pickle.dump(\n",
    "            (temp_sample_dict, temp_sample_dict_cmask), \n",
    "            open('plotting_data/single/temp_sample_dict_{}_{}.p'.format(str(mod_id), str(sim_seed)), 'wb'))\n",
    "\n",
    "        sim_file_name = ef.make_pseudodata_file(ebinmodel.temp_names_sim, ebinmodel.sim_data_dir, create_dir = False, return_name=True, sim_seed=sim_seed, \n",
    "                                        is_custom_blg=is_custom_blg, custom_blg_id=custom_blg_id)\n",
    "        ebinmodel.counts = jnp.array(np.load(sim_file_name), dtype = jnp.float32)\n",
    "\n",
    "        # cartesian gp samples\n",
    "        exp_gp_samples = temp_sample_dict_cmask['gp']\n",
    "        exp_gp_samples_cart = ef.multi_healpix_to_cart(exp_gp_samples, mask, n_pixels = n_pixels, nside = 128, progress_bar = False)\n",
    "\n",
    "        # create gp_true from scratch\n",
    "        temp_names_sim = rig_temp_sim + hyb_temp_sim + var_temp_sim # imported from settings file\n",
    "        ebinmodel.load_templates(temp_names_sim, blg_names, dif_names)\n",
    "        gp_true = ( temp_dict['S_blg'] * ebinmodel.blg_temps[0].at_bin(ebin, mask) + temp_dict['S_nfw'] * ebinmodel.nfw_temp.get_NFW2_template(gamma = temp_dict['gamma'])[~mask] )\n",
    "\n",
    "        # 1D slice of total rate\n",
    "        tot_samples = jnp.zeros(np.sum(~mask))\n",
    "        tot_names = list(temp_sample_dict_cmask.keys())\n",
    "        for tot_name in tot_names:\n",
    "            tot_samples += temp_sample_dict_cmask[tot_name]\n",
    "        tot_samples_cart = ef.multi_healpix_to_cart(tot_samples, mask, n_pixels = n_pixels, nside = 128, progress_bar = False)\n",
    "\n",
    "        sim_samples = jnp.zeros(np.sum(~mask))\n",
    "        for sim_name in temp_names_sim:\n",
    "            sim_samples += temp_dict[sim_name][~mask]\n",
    "\n",
    "        # 1D slice of residual posterior rate samples relative to truth\n",
    "        model_residuals = tot_samples - sim_samples\n",
    "        model_residuals_cart = ef.multi_healpix_to_cart(model_residuals, mask, n_pixels=n_pixels, nside = 128, progress_bar = False)\n",
    "\n",
    "        # 1D slice of residual data relative to posterior samples\n",
    "        rng_key = jax.random.PRNGKey(mod_id)\n",
    "        rng_key, key = jax.random.split(rng_key)\n",
    "        poisson_samples = jax.random.poisson(key, tot_samples)\n",
    "        data_residuals = ebinmodel.counts[ebin][~mask] - poisson_samples\n",
    "        data_residuals_cart = ef.multi_healpix_to_cart(data_residuals, mask, n_pixels = n_pixels, nside = 128, progress_bar = False)\n",
    "\n",
    "        # combine samples corresponding to different datasets\n",
    "        if len(aug_temp_sample_dict) == 0:\n",
    "            aug_temp_sample_dict = temp_sample_dict\n",
    "            aug_temp_sample_dict_cmask = temp_sample_dict_cmask\n",
    "            aug_exp_gp_samples_cart = exp_gp_samples_cart\n",
    "            aug_gp_true_cart = gp_true\n",
    "            aug_tot_samples_cart = tot_samples_cart\n",
    "            aug_model_residuals_cart = model_residuals_cart\n",
    "        else:\n",
    "            for key in temp_sample_dict.keys():\n",
    "                aug_temp_sample_dict[key] = np.concatenate((aug_temp_sample_dict[key], temp_sample_dict[key]))\n",
    "                aug_temp_sample_dict_cmask[key] = np.concatenate((aug_temp_sample_dict_cmask[key], temp_sample_dict_cmask[key]))\n",
    "            aug_exp_gp_samples_cart = np.concatenate((aug_exp_gp_samples_cart, exp_gp_samples_cart))\n",
    "            aug_gp_true_cart = np.concatenate((aug_gp_true_cart, gp_true))\n",
    "            aug_tot_samples_cart = np.concatenate((aug_tot_samples_cart, tot_samples_cart))\n",
    "            aug_model_residuals_cart = np.concatenate((aug_model_residuals_cart, model_residuals_cart))\n",
    "\n",
    "    pickle.dump(\n",
    "        (aug_temp_sample_dict, aug_temp_sample_dict_cmask, aug_exp_gp_samples_cart, aug_gp_true_cart, aug_tot_samples_cart, aug_model_residuals_cart), \n",
    "        open('plotting_data/multi/aug_temp_sample_dict_{}.p'.format(str(mod_id)), 'wb'))\n",
    "        \n",
    "    temp_sample_dict_list[mod_id] = aug_temp_sample_dict\n",
    "    temp_sample_dict_cmask_list[mod_id] = aug_temp_sample_dict_cmask\n",
    "    exp_gp_samples_cart_list[mod_id] = aug_exp_gp_samples_cart\n",
    "    gp_true_cart_list[mod_id] = aug_gp_true_cart\n",
    "    tot_samples_cart_list[mod_id] = aug_tot_samples_cart\n",
    "    model_residuals_cart_list[mod_id] = aug_model_residuals_cart\n",
    "\n",
    "pickle.dump(\n",
    "    (temp_sample_dict_list, temp_sample_dict_cmask_list, exp_gp_samples_cart_list, gp_true_cart_list, tot_samples_cart_list, model_residuals_cart_list, mask, mask_p, mask_map_cart), \n",
    "    open('plotting_data/multi/all_mismodelling_data_2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mod_id:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mod_id: 100%|██████████| 3/3 [04:56<00:00, 98.81s/it] t]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# We'll start with the difficult stuff\n",
    "# We'll start by making the single model fits\n",
    "\n",
    "corner_samples_dict = {}\n",
    "corner_keys = ['S_bub', 'S_ics', 'S_iso', 'S_pib', 'S_psc', 'S_gp', 'theta_ics', 'theta_pib']\n",
    "\n",
    "for mod_id in tqdm(mod_ids, desc = 'mod_id', position = 0):\n",
    "    data_models = ['o', 'a', 'f']\n",
    "    mod_data = data_models[int(str(mod_id)[-1]) - 1]\n",
    "    sim_name = data_file = 'canon_g1p2_{}la_v2'.format(mod_data)\n",
    "    data_dir = ef.load_data_dir(sim_name)\n",
    "\n",
    "    aug_corner_samples = []\n",
    "\n",
    "    for sim_seed in tqdm(sim_seeds, desc = 'sim_seed', position = 1, leave = False):\n",
    "        str_sim_seed = str(sim_seed)\n",
    "        \n",
    "        # load file names and data\n",
    "        fit_filename, module_name = ef.generate_fit_filename_from_ids(sim_id, temp_id, gp_id, blg_id, mod_id, svi_id, sim_seed, svi_seed)\n",
    "        fit_dir = data_dir + 'fits/' + fit_filename + '/'\n",
    "        # ef.list_files(fit_dir)\n",
    "\n",
    "        # sys.path.append(fit_dir)\n",
    "        # import importlib \n",
    "        # module = importlib.import_module(module_name)\n",
    "\n",
    "        # # Load all the variables from the module\n",
    "        # globals().update(vars(module))\n",
    "\n",
    "        file_name = ('ebin' + str_ebin + '_smp_svi_' + \n",
    "                    str_lr + '_' + str_n_steps + '_' + \n",
    "                        str_guide + '_' + str_num_particles + '_' + \n",
    "                        str_sim_seed + '_' + str_svi_seed + '.p')\n",
    "        samples_dict, _ = pickle.load(open(fit_dir + file_name, 'rb'))\n",
    "\n",
    "        corner_samples = {k : samples_dict[k] for k in corner_keys}\n",
    "        corner_samples = truncate_samples(corner_samples, 1000)\n",
    "\n",
    "        # combine samples corresponding to different datasets\n",
    "        if len(aug_corner_samples) == 0:\n",
    "            aug_corner_samples = corner_samples\n",
    "        else:\n",
    "            for key in corner_samples.keys():\n",
    "                aug_corner_samples[key] = np.concatenate((aug_corner_samples[key], corner_samples[key]))\n",
    "\n",
    "    pickle.dump(\n",
    "        aug_corner_samples, \n",
    "        open('plotting_data/multi/aug_corner_samples_{}.p'.format(str(mod_id)), 'wb')\n",
    "    )\n",
    "        \n",
    "    corner_samples_dict[mod_id] = aug_corner_samples\n",
    "\n",
    "pickle.dump(\n",
    "    corner_samples_dict, \n",
    "    open('plotting_data/multi/corner_samples_dict_2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mod_id:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mod_id: 100%|██████████| 3/3 [00:00<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_dict_list = {}\n",
    "sim_cart_list = {}\n",
    "\n",
    "for mod_id in tqdm(mod_ids, desc = 'mod_id', position = 0):\n",
    "    data_models = ['o', 'a', 'f']\n",
    "    mod_data = data_models[int(str(mod_id)[-1]) - 1]\n",
    "    sim_name = 'canon_g1p2_{}la_v2'.format(mod_data)\n",
    "    data_dir = ef.load_data_dir(sim_name)\n",
    "\n",
    "    temp_dict = np.load(data_dir + 'all_templates_ebin' + str(ebin)  + '.npy', allow_pickle=True).item()\n",
    "    temp_dict_list[mod_id] = temp_dict\n",
    "\n",
    "    sim_samples = jnp.zeros(np.sum(~mask))\n",
    "    for sim_name in temp_names_sim:\n",
    "        sim_samples += temp_dict[sim_name][~mask]\n",
    "\n",
    "    sim_cart = ef.healpix_to_cart(sim_samples, mask, n_pixels = n_pixels, nside = 128)\n",
    "    sim_cart_list[mod_id] = sim_cart\n",
    "\n",
    "pickle.dump(\n",
    "    (temp_dict_list, sim_cart_list), \n",
    "    open('plotting_data/multi/temp_dict_list_2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iso': Array([1.7143949, 1.7204459, 1.7069949, ..., 1.6685123, 1.6757793,\n",
       "        1.6803055], dtype=float32),\n",
       " 'psc': Array([7.3654763e-04, 9.7571865e-05, 2.5533074e-05, ..., 2.0816139e-04,\n",
       "        5.0771971e-05, 3.5951165e-05], dtype=float32),\n",
       " 'bub': Array([ 0.,  0.,  0., ..., -0., -0., -0.], dtype=float32),\n",
       " 'pib': Array([0.3397213 , 0.39276898, 0.40060714, ..., 0.50880885, 0.57469577,\n",
       "        0.5348137 ], dtype=float32),\n",
       " 'ics': Array([0.2891918 , 0.28664073, 0.2845911 , ..., 0.27629197, 0.27732316,\n",
       "        0.28132036], dtype=float32),\n",
       " 'blg': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'nfw': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'S_iso': Array(1.8840955, dtype=float32),\n",
       " 'S_psc': Array(3.6656773, dtype=float32),\n",
       " 'S_bub': Array(1.3591579, dtype=float32),\n",
       " 'S_pib': Array(14.448217, dtype=float32),\n",
       " 'S_ics': Array(5.6796474, dtype=float32),\n",
       " 'S_blg': Array(0.26294672, dtype=float32),\n",
       " 'S_nfw': Array(0.35982147, dtype=float32),\n",
       " 'gamma': 1.2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict_list[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_samples_dict_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtemp_samples_dict_list\u001b[49m[\u001b[38;5;241m11\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_samples_dict_list' is not defined"
     ]
    }
   ],
   "source": [
    "temp_samples_dict_list[11]['iso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_mod_id(dif_models, mod_data):\n",
    "    models = ['o', 'a', 'f']\n",
    "    num_dict = {m : str(i+1) for i, m in enumerate(models)}\n",
    "\n",
    "    mod_id = [num_dict[i] for i in dif_models]\n",
    "    mod_id.append(num_dict[mod_data])\n",
    "    mod_id = ''.join(mod_id)\n",
    "    return int(mod_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
